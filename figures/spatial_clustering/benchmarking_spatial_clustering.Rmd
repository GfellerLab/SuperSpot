---
title: "Benchmarking Spatial Clustering Algorithms"
author: "Matei Teleman"
date: "2023-10-30"
output: html_document
editor_options: 
  chunk_output_type: console
---



```{r}
reticulate::use_miniconda("/Users/admin/miniconda3")
```


## Import libraries

```{r}
library(igraph)
library(pbapply)
library(tidyr)
library(tidyverse)
library(igraph)
library(SuperCell)
library(SeuratObject)
library(Seurat)
library(patchwork)
library(ggplot2)
library(dplyr)
library(hdf5r)
library(scales)
library(ggpubr)
library(networkD3)
library(ggforce)
library(clusterProfiler)
library(SuperSpot)
```

## Python Clustering methods
```{python}
import anndata as ad
import squidpy as sq
import pandas as pd
import scanpy as sc
import numpy as np
import matplotlib.pyplot as plt
import random
import os
import torch
from sklearn import metrics
import multiprocessing as mp
import GraphST
import sys

import STAGATE
```

### GraphST

```{python}
seed_values = [random.randint(1, 10000) for _ in range(10)]
adata = sc.read_visium(path="/Users/admin/Downloads/151673", count_file='filtered_feature_bc_matrix.h5')
adata.var_names_make_unique()
```


```{python}
from GraphST import GraphST
# Run device, by default, the package is implemented on 'cpu'. We recommend using GPU.
device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')

# the location of R, which is necessary for mclust algorithm. Please replace the path below with local R installation path
os.environ['R_HOME'] = "/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources"
```

```{python}
for i in range (0,10):
  # the number of clusters
  n_clusters = 7
  dataset = '151673'
  # define model
  model = GraphST.GraphST(adata, device=device,random_seed=seed_values[i])
  # train model
  adata = model.train()
  # set radius to specify the number of neighbors considered during refinement
  radius = 50
  tool = 'mclust' # mclust, leiden, and louvain
  # clustering
  from GraphST.utils import clustering
  clustering(adata, n_clusters, radius=radius, method=tool, refinement=True) # For DLPFC dataset, we use optional refinement   step.
  print(i)
  adata.obs['mclust'].to_excel(f"/Users/admin/Documents/These/Output/SC_DLS/Benchmarking_Mouse_Cortex_v2/spot/graphST_clustering_{i}.xlsx")

```

### STAGATE
```{python}
os.environ['R_HOME'] = "/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources"
os.environ['R_USER'] = '/Users/admin/miniconda3/lib/python3.10/site-packages/rpy2'
adata = sc.read_visium(path="/Users/admin/Downloads/151673", count_file='filtered_feature_bc_matrix.h5')
adata.var_names_make_unique()
#Normalization
sc.pp.highly_variable_genes(adata, flavor="seurat_v3", n_top_genes=3000)
sc.pp.normalize_total(adata, target_sum=1e4)
sc.pp.log1p(adata)
```

```{python}
import tensorflow.compat.v1 as tf


for i in range (0,10):
  tf.disable_eager_execution()

  STAGATE.Cal_Spatial_Net(adata, rad_cutoff=150)
  STAGATE.Stats_Spatial_Net(adata)

  adata = STAGATE.train_STAGATE(adata, alpha=0,random_seed=seed_values[i])


  sc.pp.neighbors(adata, use_rep='STAGATE')
  sc.tl.umap(adata)
  adata = STAGATE.mclust_R(adata, used_obsm='STAGATE', num_cluster=7)

  #sc.pl.spatial(adata, color=["mclust"], title=['STAGATE'])
  adata.obs['mclust'].to_excel(f"/Users/admin/Documents/These/Output/SC_DLS/Benchmarking_Mouse_Cortex_v2/spot/STAGATE_clustering{i}.xlsx")

```

### CellCharter

```{r}
reticulate::use_miniconda("/Users/admin/miniconda3/envs/cellcharter-env")
```


```{python}
import anndata as ad
import squidpy as sq
import cellcharter as cc
import pandas as pd
import scanpy as sc
import scvi
import numpy as np
import matplotlib.pyplot as plt
import random

seed_values = [random.randint(1, 10000) for _ in range(10)]


adata = sc.read_visium(path="/Users/admin/Downloads/151673", count_file='filtered_feature_bc_matrix.h5')
adata.var_names_make_unique()
adata

# Remove negative probes
adata = adata[:, [c for c in adata.var_names if 'NegPrb' not in c]].copy()
    
adata.obs['sample'] = "151673"


```

```{python}

adata.obs['sample'] = pd.Categorical(adata.obs['sample'])
#adata.uns['spatial'] = pd.Categorical(adata.uns['spatial'])
adata
```

```{python}
sc.pp.filter_genes(adata, min_counts=3)
adata
adata.layers["counts"] = adata.X.copy()

sc.pp.normalize_total(adata, target_sum=1e6)
sc.pp.log1p(adata)

adata
```

```{python}
for i in range (0,10):
  scvi.settings.seed = seed_values[i]
  scvi.model.SCVI.setup_anndata(
    adata, 
    layer="counts", 
    batch_key='sample'
  )

  model = scvi.model.SCVI(adata)
  model.train(early_stopping=True, enable_progress_bar=True)

  adata.obsm['X_scVI'] = model.get_latent_representation(adata).astype(np.float32)

  sq.gr.spatial_neighbors(adata, library_key='sample', coord_type='generic', delaunay=True, spatial_key='spatial')
  cc.gr.remove_long_links(adata)

  cc.gr.aggregate_neighbors(adata, n_layers=3, use_rep='X_scVI', out_key='X_cellcharter', sample_key='sample')



  autok = cc.tl.ClusterAutoK(
     n_clusters=(2,10), 
      max_runs=10, 
      model_params=dict(
          random_state=seed_values[i]
          # If running on GPU
          #trainer_params=dict(accelerator='gpu', devices=1)
      )
  )

  autok.fit(adata, use_rep='X_cellcharter')

  #plt.close()
  #cc.pl.autok_stability(autok)
  #plt.show()
  #plt.close()
  adata.obs['cluster_cellcharter'] = autok.predict(adata, use_rep='X_cellcharter',k=7)

  sq.pl.spatial_scatter(
      adata, 
      color=['cluster_cellcharter'], 
      library_key='sample',  
      size=1, 
      img=None,
      spatial_key='spatial',
      palette='Set2',
      #connectivity_key='spatial_connectivities',
      #img_alpha=0.3,
      figsize=(15,15),
      ncols=1,
      #library_id=adata.obs['sample'].unique(),
      library_id=['151673'],
  )

  #plt.show()
  #plt.close()
  adata.obs['cluster_cellcharter'].to_excel(f"/Users/admin/Documents/These/Output/SC_DLS/Benchmarking_Mouse_Cortex_v2/spot/cellcharter_clustering_{i}.xlsx")

```

## Cluster in R
```{r}
library("DR.SC")
library(Seurat)
library(SeuratData)
#library(BPCells)
library(dplyr)
options(Seurat.object.assay.version = "v5")
seed_values <- sample(1:10000, 10, replace = FALSE)

dlpfc151673 <- Load10X_Spatial("/Users/admin/Downloads/151673")

count <- dlpfc151673@assays$Spatial@layers$counts
meta_data <- data.frame(row=dlpfc151673@images[["slice1"]]@coordinates[["row"]], col=dlpfc151673@images[["slice1"]]@coordinates[["col"]])
row.names(meta_data) <- colnames(count)
## create Seurat object
so <- CreateSeuratObject(counts=count, meta.data = meta_data)
head(so)

# standard log-normalization
so <- NormalizeData(so)
# choose 500 highly variable features
seu <- FindVariableFeatures(so, nfeatures = 500, verbose = T)

```

```{r}
for (i in 1:10){
### Given K
seu <- DR.SC(seu, K=7, platform = 'Visium', verbose=F)
#Visualization

spatialPlotClusters(seu)
#Show the tSNE plot based on the extracted features from DR-SC.

drscPlot(seu)
#Show the UMAP plot based on the extracted features from DR-SC.

dlpfc151673@meta.data$dr.sc <- seu$spatial.drsc.cluster
SpatialDimPlot(dlpfc151673,group.by = "dr.sc")
dr.sc.df <- dlpfc151673@meta.data[,"dr.sc",drop = F]
dr.sc.df$cell <- colnames(dlpfc151673)

writexl::write_xlsx(dr.sc.df,path = paste0("/Users/admin/Documents/These/Output/SC_DLS/Benchmarking_Mouse_Cortex_v2/spot/dr_sc_clustering_",i,".xlsx"))

}
```

```{r}
library(BayesSpace)
#dlpfc151673 <- NormalizeData(dlpfc151673)

insh <- as.SingleCellExperiment(dlpfc151673)
insh@colData@listData$row <- dlpfc151673@images[["slice1"]]@coordinates[["row"]]
insh@colData@listData$col <- dlpfc151673@images[["slice1"]]@coordinates[["col"]]
insh@colData@listData$imagerow <- dlpfc151673@images[["slice1"]]@coordinates[["imagerow"]]
insh@colData@listData$imagecol <- dlpfc151673@images[["slice1"]]@coordinates[["imagecol"]]

for (i in 1:10){
  set.seed(seed_values[i])
  insh <- spatialPreprocess(insh, platform="Visium",n.PCs=7, n.HVGs=2000, log.normalize=T)
  qPlot(insh)

  set.seed(seed_values[i])
  insh <- spatialCluster(insh, q=7, platform="Visium", d=7,init.method="mclust", model="t", gamma=2,nrep=1000, burn.in=100,save.chain=TRUE)
  head(colData(insh))

  clusterPlot(insh)
  bayespace.df <- colData(insh)[,"spatial.cluster",drop = F] %>% as.data.frame()
  bayespace.df$cell <- colnames(dlpfc151673)
  
  writexl::write_xlsx(bayespace.df,path = paste0("/Users/admin/Documents/These/Output/SC_DLS/Benchmarking_Mouse_Cortex_v2/spot/bayespace_clustering_",i,".xlsx"))
}

```

```{r}
dr.sc.df <- dlpfc151673@meta.data[,"dr.sc",drop = F]
dr.sc.df$cell <- colnames(dlpfc151673)

bayespace.df <- colData(insh)[,"spatial.cluster",drop = F] %>% as.data.frame()
bayespace.df$cell <- colnames(dlpfc151673)

writexl::write_xlsx(dr.sc.df,path = "./Benchmarking Mouse Cortex/dr_sc_clustering.xlsx")
writexl::write_xlsx(bayespace.df,path = "./Benchmarking Mouse Cortex/bayespace_clustering.xlsx")
```

